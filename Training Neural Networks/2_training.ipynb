{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c98a090",
   "metadata": {},
   "source": [
    "# L2 - Training\n",
    "\n",
    "## MNIST Classification\n",
    "\n",
    "The MNIST dataset consists of $28\\times28$ pixel images of handwritten digits and the task is to recognize the digits.\n",
    "In this notebook, we use this dataset to demonstrate how to implement a few of the discussed concepts of neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8b8f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08e514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: (60000, 28, 28) of type: uint8\n",
      "Training labels: (60000,) of type: uint8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training images: {x_train.shape} of type: {x_train.dtype}\")\n",
    "print(f\"Training labels: {y_train.shape} of type: {y_train.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8382a9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize examples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_train[i].astype(\"uint8\"))\n",
    "    plt.title(int(y_train[i]))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee41a1",
   "metadata": {},
   "source": [
    "## Base Model\n",
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39244c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_base_model(input_shape, classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Flatten images to 1D vectors\n",
    "    x = layers.Flatten()(inputs)\n",
    "    # normalize inputs\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    \n",
    "    # fully connected layers\n",
    "    # NOTE: we could configure the dense layers directly with the required activation as in the outputs case\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    outputs = layers.Dense(classes, activation='softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb015717",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "base_model = make_base_model(x_train.shape[1:], len(np.unique(y_train)))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2b413",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7564b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure training algorithm, loss function and metrics\n",
    "base_model.compile(\n",
    "    # use stochastic gradient descent with base learning rate\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    # use crossentropy loss for multiple classes\n",
    "    # SparseCategoricalCrossentropy is a convenience function, which does the one-hot encoding of the labels for us\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # configure set of metrics (must be defined in tf.keras.metrics)\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "009242b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.4492 - accuracy: 0.8778\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.2189 - accuracy: 0.9373\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.1662 - accuracy: 0.9521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b71434340>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(\n",
    "    # training data\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21baca3",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad3892f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 917us/step - loss: 0.1450 - accuracy: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14495599269866943, 0.9563999772071838]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(\n",
    "    x=x_test, y=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58328106",
   "metadata": {},
   "source": [
    "### Saving and Restoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef156608",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = 'base_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e515b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to given path\n",
    "base_model.save(base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0b89cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete model\n",
    "del base_model\n",
    "\n",
    "# restore model from saved state\n",
    "base_model = tf.keras.models.load_model(base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4356821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 890us/step - loss: 0.1450 - accuracy: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14495599269866943, 0.9563999772071838]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(\n",
    "    x=x_test, y=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c89bf3",
   "metadata": {},
   "source": [
    "## Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "010c60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_initialization_model(input_shape, classes, kernel_initializer, bias_initializer):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Flatten images to 1D vectors\n",
    "    x = layers.Flatten()(inputs)\n",
    "    # normalize inputs\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    \n",
    "    # fully connected layers\n",
    "    # NOTE: we could configure the dense layers directly with the required activation as in the outputs case\n",
    "    x = layers.Dense(256, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dense(128, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    outputs = layers.Dense(classes, activation='softmax', \n",
    "                           kernel_initializer=kernel_initializer, \n",
    "                           bias_initializer=bias_initializer)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2e918",
   "metadata": {},
   "source": [
    "### Constant Zero Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "511c909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_model = make_initialization_model(x_train.shape[1:], len(np.unique(y_train)),\n",
    "                                       tf.keras.initializers.Zeros(), tf.keras.initializers.Zeros())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59980a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c08af43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 2.3015 - accuracy: 0.1117\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 2.3014 - accuracy: 0.1124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b71525cd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_model.fit(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6010ede",
   "metadata": {},
   "source": [
    "### Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8701f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model = make_initialization_model(x_train.shape[1:], len(np.unique(y_train)),\n",
    "                                       tf.keras.initializers.RandomNormal(mean=0.0, stddev=1., seed=42), \n",
    "                                       # normally, biases are zero initialized by default\n",
    "                                       tf.keras.initializers.Zeros())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6538de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "426b6b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 9.8584 - accuracy: 0.6856\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 1.0715 - accuracy: 0.7317\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.8351 - accuracy: 0.7867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b851a7cd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.fit(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ce6d7",
   "metadata": {},
   "source": [
    "### He Initialization\n",
    "\n",
    "We have seen Xavier initalization already in the base example, since this is the default initialization scheme for a dense\n",
    "layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b38adc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "he_model = make_initialization_model(x_train.shape[1:], len(np.unique(y_train)),\n",
    "                                       tf.keras.initializers.HeNormal(), \n",
    "                                       tf.keras.initializers.Zeros())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "978c1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "374bb5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.4184 - accuracy: 0.8853\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.2113 - accuracy: 0.9396\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.1606 - accuracy: 0.9534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b715218e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_model.fit(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3722910",
   "metadata": {},
   "source": [
    "$\\Rightarrow$ There does not seem to be much difference between Xavier and He initialization in this case.\n",
    "This is not unexpected, since problems with Xavier initialization should become apparent only for deeper networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a2984",
   "metadata": {},
   "source": [
    "## Training Algorithms\n",
    "\n",
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "904bb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_model = make_base_model(x_train.shape[1:], len(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb0ebfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_model.compile(\n",
    "    # simply change the optimizer to one implemented in tf.keras.optimizers\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0b86eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.1910 - accuracy: 0.9421\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0861 - accuracy: 0.9737\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0627 - accuracy: 0.9803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b5805b130>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_model.fit(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "503f3747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 891us/step - loss: 0.0792 - accuracy: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07922563701868057, 0.9764000177383423]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_model.evaluate(\n",
    "    x=x_test, y=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f92d5fe",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "### Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80b6c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regularization_model(input_shape, classes, kernel_regularizer):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Flatten images to 1D vectors\n",
    "    x = layers.Flatten()(inputs)\n",
    "    # normalize inputs\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    \n",
    "    # fully connected layers\n",
    "    x = layers.Dense(256, kernel_regularizer=kernel_regularizer)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dense(128, kernel_regularizer=kernel_regularizer)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    outputs = layers.Dense(classes, activation='softmax', \n",
    "                           kernel_regularizer=kernel_regularizer)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f88669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay_model = make_regularization_model(x_train.shape[1:], len(np.unique(y_train)),\n",
    "                                               tf.keras.regularizers.L2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05d36357",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5614f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.0053 - accuracy: 0.8826\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.8135 - accuracy: 0.9002\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.7957 - accuracy: 0.9037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b7108f6d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_decay_model.fit(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbda17",
   "metadata": {},
   "source": [
    "$\\Rightarrow$ Obvsiously, we overdid the regularization here - this requires tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b6448",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23ee8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_model = make_base_model(x_train.shape[1:], len(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8053f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d08194de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "my_callbacks = [\n",
    "    # configure early stopping -> by default, stop if validation loss did not improve for three epochs\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3),\n",
    "    # reduce learning rate if training stalled - NOTE: you probably want to set the patience levels higher for both\n",
    "    # early stopping and this learning rate reduction\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=2),\n",
    "    # log training progress for TensorBoard\n",
    "    tf.keras.callbacks.TensorBoard('log_dir'),\n",
    "    # log training progress as CSV file\n",
    "    # tf.keras.callbacks.CSVLogger('training.log')\n",
    "    # save currently best performing model based on validation loss\n",
    "    # tf.keras.callbacks.ModelCheckpoint(filepath='best.h5', save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3935b26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3000/3000 [==============================] - 5s 1ms/step - loss: 0.2167 - accuracy: 0.9346 - val_loss: 0.1400 - val_accuracy: 0.9572 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.0927 - accuracy: 0.9707 - val_loss: 0.0964 - val_accuracy: 0.9696 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.0656 - accuracy: 0.9791 - val_loss: 0.1099 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0475 - accuracy: 0.9849 - val_loss: 0.0981 - val_accuracy: 0.9727 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0735 - val_accuracy: 0.9812 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0759 - val_accuracy: 0.9817 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0802 - val_accuracy: 0.9803 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0798 - val_accuracy: 0.9818 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b85285790>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_model.fit(\n",
    "    x=x_train, y=y_train,\n",
    "    # configure validation split\n",
    "    validation_split=0.2,\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    # set callbacks\n",
    "    callbacks=my_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f595c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 940us/step - loss: 0.0647 - accuracy: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06472136080265045, 0.9837999939918518]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_model.evaluate(\n",
    "    x=x_test, y=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9e419",
   "metadata": {},
   "source": [
    "$\\Rightarrow$ so far the best, but we also trained longerâ€¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a184678",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c59c09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dropout_model(input_shape, classes, dropout_config):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Flatten images to 1D vectors\n",
    "    x = layers.Flatten()(inputs)\n",
    "    # normalize inputs\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    \n",
    "    # fully connected layers\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    if dropout_config[0] is not None:\n",
    "        x = layers.Dropout(dropout_config[0])(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    if dropout_config[1] is not None:\n",
    "        x = layers.Dropout(dropout_config[1])(x)\n",
    "    \n",
    "    outputs = layers.Dense(classes, activation='softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c91de3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_dropout_model = make_dropout_model(x_train.shape[1:], len(np.unique(y_train)), [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecbcb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_dropout_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f9b6930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 6s 1ms/step - loss: 0.4051 - accuracy: 0.8778\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.2304 - accuracy: 0.9328\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.1981 - accuracy: 0.9433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b90c3e850>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heavy_dropout_model.fit(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9e49f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_dropout_model = make_dropout_model(x_train.shape[1:], len(np.unique(y_train)), [None, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "613763ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_dropout_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0464a3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.2118 - accuracy: 0.9359\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0966 - accuracy: 0.9702\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0690 - accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b71550580>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_dropout_model.fit(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0e259cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 911us/step - loss: 0.0799 - accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07994246482849121, 0.9778000116348267]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_dropout_model.evaluate(\n",
    "    x=x_test, y=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07d43c",
   "metadata": {},
   "source": [
    "$\\Rightarrow$ possibly some advantage of the model with light dropout compared to the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a58c1c",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f2fbc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batchnorm_model(input_shape, classes, batchnorm_config):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Flatten images to 1D vectors\n",
    "    x = layers.Flatten()(inputs)\n",
    "    # normalize inputs\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    \n",
    "    # fully connected layers\n",
    "    x = layers.Dense(256)(x)\n",
    "    if batchnorm_config[0] is True:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    if batchnorm_config[1] is True:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    outputs = layers.Dense(classes, activation='softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c50dabb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchnorm_model = make_batchnorm_model(x_train.shape[1:], len(np.unique(y_train)), [True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69944e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchnorm_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d14fa94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2422 - accuracy: 0.9265\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.1272 - accuracy: 0.9605\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.1027 - accuracy: 0.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b600298b0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchnorm_model.fit(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a11719",
   "metadata": {},
   "source": [
    "$\\Rightarrow$ does not seem to do that much here, but this is a rather shallow network and we train for few epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9928c",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14439c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy arrays to TensorFlow dataset for augmentation\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train.reshape((-1, 28, 28, 1)), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a886d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define augmentations to apply\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(0.1),\n",
    "        # move image by 20% up/down/left/right - determine pixels to fill in by boarder pixels\n",
    "        layers.RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode='nearest')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "caa059c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply `data_augmentation` to the training images.\n",
    "train_ds = train_ds.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "# Prefetching samples in GPU memory helps maximize GPU utilization.\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# shuffle and batch dataset\n",
    "train_ds = train_ds.shuffle(100).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5cfa4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7687bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_model = make_base_model(x_train.shape[1:], len(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70418a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa10a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 6s 1ms/step - loss: 0.1918 - accuracy: 0.9429\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0866 - accuracy: 0.9737\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0601 - accuracy: 0.9816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b71d4c970>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment_model.fit(\n",
    "    train_ds,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1df476a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 905us/step - loss: 0.0973 - accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09725691378116608, 0.9732999801635742]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment_model.evaluate(\n",
    "    x=x_test, y=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8773640c",
   "metadata": {},
   "source": [
    "$\\Rightarrow$ as in many of these cases, we would need to train for longer to benefit from the change"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
